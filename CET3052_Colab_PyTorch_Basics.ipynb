{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annesjyu/NLP2/blob/main/CET3052_Colab_PyTorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y18okPMJRLyt"
      },
      "source": [
        "# PyTorch and Neural Network Basics\n",
        "\n",
        "Learning objectives\n",
        "\n",
        "* Computational Graphs\n",
        "* Tensors\n",
        "* Operations with tensors\n",
        "* Indexing, slicing, and joining\n",
        "* Computing gradients\n",
        "* Use CUDA tensors with GPUs (need GPU)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisite Terms\n",
        "\n",
        "\n",
        "1.   features\n",
        "2.   targets\n",
        "3.   models\n",
        "4.   parameters\n",
        "5.   hyperparameters\n",
        "6.   predictions\n",
        "7.   loss functions\n",
        "8.   learning/training\n",
        "9.   testing"
      ],
      "metadata": {
        "id": "mdBqjzqZu4kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computational Graph\n",
        "\n",
        "It is essentially a graph where nodes represent operations or calculations, and edges represent the tensors (or arrays of data) that flow between these operations.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*HK6gaBlCJLQOTldCURi7qQ.gif\" height=200>\n",
        "\n",
        "Above computational graph is used to implement a function $f(A,B,C) =(A*B)+C$.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*d3uM1IwDZWqvEU2G0p0gxA.gif\" height=200>\n",
        "\n",
        "Above computational graph is used to implement a basic neural network layer."
      ],
      "metadata": {
        "id": "zRqJHr8PooRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython  import display\n",
        "from IPython.display import HTML\n",
        "\n",
        "iframe = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hCP1vGoCdYU?si=O63OoSfNlDHjZENc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>'\n",
        "\n",
        "display.display(HTML(iframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "g60-3CnemKLk",
        "outputId": "42940397-b2ac-4b79-d764-4523f96dae02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/hCP1vGoCdYU?si=O63OoSfNlDHjZENc\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Static vs. Dynamic Computational Graph\n",
        "Tensorflow and PyTorch as implemenation libraries compute the above types of graphs using multithreading and graph optimization to reduce the training time and the layers of computation. But they are different in terms of implementation.\n",
        "\n",
        "### **Static Computational Graphs** (TensorFlow)\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:504/format:webp/0*4UHwQnsmUjyD7VtW.gif\">\n",
        "\n",
        "> `Stochastic Gradient Descent (SGD)` is a widely used optimization algorithm for training various types of models.\n",
        "\n",
        "> `Gradient Descent` is the fundamental algorithm for minimizing the loss function of a model by iteratively moving towards the minimum of the function.\n",
        "\n",
        "> `Stochastic` is unlike traditional gradient descent, which uses the entire dataset to calculate the gradient of the loss function (which can be computationally expensive and slow), it improves efficiency by using a random subset of the data (a minibatch) to compute an approximation of the gradient. This makes the algorithm much faster and able to be applied to online learning scenarios.\n",
        "\n",
        "#### Definition\n",
        "\n",
        "A static computational graph means the graph's structure is defined and compiled before it's run. Once compiled, it cannot be changed. This is what TensorFlow used initially (up until v2.0, where it embraced more dynamic graphs through Eager Execution).\n",
        "\n",
        "#### Advantages\n",
        "\n",
        "* Efficiency\n",
        "\n",
        "Once compiled, the graph can be optimized, leading to faster execution and less resource consumption.\n",
        "\n",
        "* Portability\n",
        "\n",
        "The graph can be saved, deployed, and run without the code that generated it.\n",
        "\n",
        "* Visualization\n",
        "\n",
        "Easy to visualize and debug using tools like TensorBoard.\n",
        "\n",
        "#### Disadvantages\n",
        "\n",
        "* Less Intuitive\n",
        "\n",
        "Harder for Python programmers to debug and understand, as the code doesn't execute Python line by line.\n",
        "\n",
        "* Flexibility\n",
        "\n",
        "Less flexible in changing the graph during runtime, making it difficult for dynamic models and research.\n",
        "\n",
        "### Dynamic Computational Graphs (PyTorch)\n",
        "\n",
        "#### Definition\n",
        "\n",
        "A dynamic computational graph, also known as an \"imperative\" or \"define-by-run\" graph, is constructed on the fly during execution. This approach is used by PyTorch.\n",
        "\n",
        "#### Advantages\n",
        "\n",
        "* Intuitiveness\n",
        "\n",
        "More intuitive and pythonic. The graph is built as the code is run, making it easier to understand and debug.\n",
        "\n",
        "* Flexibility\n",
        "\n",
        "Easy to change and adapt the graph dynamically, which is particularly useful for models where the structure changes every iteration (e.g., with variable input lengths or recursive neural networks).\n",
        "\n",
        "#### Disadvantages\n",
        "\n",
        "* Overhead\n",
        "\n",
        "The flexibility can come with a runtime overhead, as the graph needs to be built from scratch at each iteration.\n",
        "\n",
        "* Optimization\n",
        "\n",
        "Less opportunity for upfront optimization compared to static graphs."
      ],
      "metadata": {
        "id": "LVT-06PnWLwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Installing PyTorch"
      ],
      "metadata": {
        "id": "kQ_TbumOkWT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JEKsvhVRLyv",
        "outputId": "990ad6c6-0590-46ef-bf67-87f0bb7abd96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7aef6db6b5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrO2Vts_RLyw"
      },
      "source": [
        "## Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5c9p-xRLyw"
      },
      "source": [
        "* Scalar is a single number. Rank 0 tensor.\n",
        "* Vector is an array of numbers - Rank 1 tensor.\n",
        "* Matrix is a 2-D array of numbers - Rank 2 tensor.\n",
        "* Tensors are N-D arrays of numbers - Rank N tensor.\n",
        "\n",
        "For example, a 4x4x4 tensor looks like the below,\n",
        "\n",
        "<img src=\"https://media.licdn.com/dms/image/D5612AQEBqlkZkHGO9g/article-cover_image-shrink_600_2000/0/1707758899801?e=2147483647&v=beta&t=DoTQT8iLr0ePf-efbAMn5rd5PmiXZ3Vj_Yaewnr16j0\" width=300 height=250>\n",
        "\n",
        "**Reference**\n",
        "\n",
        "Dabhade, P. (2024). \"*Exploring Tensors in PyTorch: A Beginner's Guide*\". [Link](https://www.linkedin.com/pulse/exploring-tensors-pytorch-beginners-guide-pratik-dabhade-jpjjc/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtTf6U6JRLyw"
      },
      "source": [
        "#### Creating Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VpzmgkFRLyw"
      },
      "source": [
        "You can create tensors by specifying the shape as arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaKoNb2pRLyw"
      },
      "outputs": [],
      "source": [
        "def describe(x):\n",
        "    print(\"Type: {}\".format(x.type()))\n",
        "    print(\"Shape/size: {}\".format(x.shape))\n",
        "    print(\"Values: \\n{}\".format(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tensor with 2 rows, 3 columns, values from a uniform distribution on the interval $[0,1)$."
      ],
      "metadata": {
        "id": "_MzGUSt6tcb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0bSM51RLyw",
        "outputId": "a641e0f9-885d-4449-a992-2452e236c172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[-2.7288e-02,  4.4100e-41, -2.1332e-02],\n",
            "        [ 4.4100e-41, -2.7288e-02,  4.4100e-41]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.Tensor(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.** Can you create a tensor with a dimension of (3, 4, 5)?"
      ],
      "metadata": {
        "id": "lAL-HprxCn_7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "49aUgRU5C7Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tensor from the standard normal distribution."
      ],
      "metadata": {
        "id": "czyH2fn0tlmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vpIjPeRLyw",
        "outputId": "99068c03-18ca-4fd6-b8b9-52a9605cec6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.0461,  0.4024, -1.0115],\n",
            "        [ 0.2167, -0.6123,  0.5036]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.randn(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CPi-UNURLyx"
      },
      "source": [
        "It's common in prototyping to create a tensor with some values and a specific shape. For example, You can initialize a tensor with dimension of (2,3) and values of **ones** or **zeros**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKHrU1V2RLyx",
        "outputId": "dda1d7b0-3218-47a1-a45f-2bff2ead2dfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor with zeros\n",
        "describe(torch.zeros(2, 3))\n",
        "\n",
        "# Tensor with ones\n",
        "x = torch.ones(2, 3)\n",
        "describe(x)\n",
        "\n",
        "# Any function with an underscore refers to an in-place operation.\n",
        "x.fill_(5)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjRIGQUsRLyx"
      },
      "source": [
        "Note:\n",
        "\n",
        "* Tensors can be initialized and then filled in place.\n",
        "\n",
        "* Operations that end in an underscore (`_`) are in place operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH7iTY_eRLyy",
        "outputId": "ba7efbf8-ef87-4365-cea0-942b82188886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor, then chained with functions\n",
        "x = torch.Tensor(3,4).fill_(5)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Q9-X4DRLyy"
      },
      "source": [
        "Tensors can be initialized from a list of lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpBA-XHMRLyy",
        "outputId": "ac6fb7b6-0f22-4939-b5f1-acaf186ef849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [2., 4.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1, 2,],\n",
        "                  [2, 4,]])\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVhRwCIRLyy"
      },
      "source": [
        "Tensors can be initialized from numpy matrices. It is important to convert between NumPy arrays and PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owRb0DnqRLyy",
        "outputId": "f9377e72-b34d-46c7-f4ca-e3be89f7d17e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.4993, 0.7065, 0.7251],\n",
            "        [0.5370, 0.9519, 0.9724]], dtype=torch.float64)\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "npy = np.random.rand(2, 3)\n",
        "describe(torch.from_numpy(npy))\n",
        "print(npy.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.** What is the difference between numpy array and tensor?\n",
        "\n",
        "**NumPy Arrays** are designed for CPU use.\n",
        "\n",
        "**Tensors** are designed to run on both CPUs and GPUs, facilitating massive parallel computing.\n",
        "\n",
        "There are other differences...\n"
      ],
      "metadata": {
        "id": "jmoYpt0bFGXP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJKbo270RLyy"
      },
      "source": [
        "#### Tensor Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZe9JkcRLyy"
      },
      "source": [
        "The FloatTensor has been the default tensor that we have been creating so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOqMMPsyRLyy",
        "outputId": "7e4de4e5-8663-4503-eea3-6f98a0083175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use contructors - FloatTensor, LongTensor, or use a **typecasting** method, `dtype`."
      ],
      "metadata": {
        "id": "9idBF6GWv02W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vhR-6mRLyz",
        "outputId": "550106a9-2516-4fc4-ba5e-ab52bc92ccda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "describe(x)\n",
        "\n",
        "x = x.long()\n",
        "describe(x)\n",
        "\n",
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]], dtype=torch.int64)\n",
        "describe(x)\n",
        "\n",
        "x = x.float()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Operations"
      ],
      "metadata": {
        "id": "tT5BuOhWHXIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Math Operations"
      ],
      "metadata": {
        "id": "2TmEx8FtgZQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZGywBI_RLyz",
        "outputId": "ef0cd844-d10d-420d-cd82-2d2778d1ca20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.2310,  0.6931, -0.2669],\n",
            "        [ 2.1785,  0.1021, -0.2590]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scu7zeivRLyz",
        "outputId": "94b778ab-d191-4737-f0f3-72802cdf0ce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.4619,  1.3862, -0.5337],\n",
            "        [ 4.3569,  0.2043, -0.5180]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.4619,  1.3862, -0.5337],\n",
            "        [ 4.3569,  0.2043, -0.5180]])\n"
          ]
        }
      ],
      "source": [
        "# plus\n",
        "describe(x + x)\n",
        "# add func\n",
        "describe(torch.add(x, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Concatenation and Joining"
      ],
      "metadata": {
        "id": "gLpB0EORgjid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP-gisPgRLyz",
        "outputId": "9a18ffb1-eb5b-4432-eaa9-eb3e734d6f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([6])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EE_sGHzRLyz",
        "outputId": "d4c967b1-ba19-4cea-a538-144c65257da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "# Reshape\n",
        "x = x.view(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenation\n",
        "describe(torch.cat([x, x], dim=0))\n",
        "describe(torch.cat([x, x], dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtpYEz5fVQq",
        "outputId": "9f003409-a7be-410b-e4e6-67f633e21ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe(torch.stack([x, x], dim=0))\n",
        "describe(torch.stack([x, x], dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrgS1ZgfoHK",
        "outputId": "0c804b81-8017-4a73-d256-50c71aa851c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [0, 1, 2]],\n",
            "\n",
            "        [[3, 4, 5],\n",
            "         [3, 4, 5]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHqoGp5bRLy0",
        "outputId": "4234c126-aa11-48c0-dd59-e7d36f53fcb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([3, 5, 7])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([ 3, 12])\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "describe(torch.sum(x, dim=0))\n",
        "describe(torch.sum(x, dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQh8MNLzRLy0",
        "outputId": "b5a0a1e4-9ad1-44e0-fd0b-09fd42c1a8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "describe(torch.transpose(x, 0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4bAWWjRRLy0",
        "outputId": "dfda14b7-b4ae-430b-d794-c7f06885e48a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 2])\n",
            "Values: \n",
            "tensor([[0, 1]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "1\n"
          ]
        }
      ],
      "source": [
        "describe(x)\n",
        "\n",
        "describe(x[:1, :2])\n",
        "describe(x[0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCAtx77lRLy0",
        "outputId": "f8a939a3-c01d-4ada-f9db-08b7381ee0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2])\n",
            "\n",
            "\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[0, 2],\n",
            "        [3, 5]])\n"
          ]
        }
      ],
      "source": [
        "indices = torch.LongTensor([0, 2])\n",
        "print(indices)\n",
        "print(\"\\n\")\n",
        "describe(x)\n",
        "describe(torch.index_select(x, dim=1, index=indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UHHRY9eRLy0",
        "outputId": "3cb38df1-b034-4235-d4e2-77f64a16700a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0])\n",
            "\n",
            "\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [0, 1, 2]])\n"
          ]
        }
      ],
      "source": [
        "indices = torch.LongTensor([0, 0])\n",
        "print(indices)\n",
        "print(\"\\n\")\n",
        "\n",
        "describe(x)\n",
        "describe(torch.index_select(x, dim=0, index=indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw4AOxtiRLy0",
        "outputId": "ea584d17-7726-42d0-9778-28879c86af01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1])\n",
            "tensor([0, 1])\n",
            "\n",
            "\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0, 4])\n"
          ]
        }
      ],
      "source": [
        "row_indices = torch.arange(2).long()\n",
        "col_indices = torch.LongTensor([0, 1])\n",
        "\n",
        "print(row_indices)\n",
        "print(col_indices)\n",
        "print(\"\\n\")\n",
        "\n",
        "describe(x)\n",
        "describe(x[row_indices, col_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMB7qOEpRLy0"
      },
      "source": [
        "Long Tensors are used for indexing operations and mirror the `int64` numpy type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO6X4Q96RLy0",
        "outputId": "2993188f-f75e-49c3-f80d-ac1bb4a4cecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "torch.int64\n",
            "int64\n"
          ]
        }
      ],
      "source": [
        "x = torch.LongTensor([[1, 2, 3],\n",
        "                      [4, 5, 6],\n",
        "                      [7, 8, 9]])\n",
        "describe(x)\n",
        "print(x.dtype)\n",
        "print(x.numpy().dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR8c6UsXRLy1"
      },
      "source": [
        "You can convert a FloatTensor to a LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85jb9DSyRLy1",
        "outputId": "f1fa8e22-200d-4225-95f9-95b79270dd9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                       [4, 5, 6],\n",
        "                       [7, 8, 9]])\n",
        "x = x.long()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jruGKEGQRLy1"
      },
      "source": [
        "### Special Tensor initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLfQHZHQRLy1"
      },
      "source": [
        "We can create a vector of incremental numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNmuEaGeRLy2",
        "outputId": "bcc168b8-bff8-48bc-86b4-5750464d3b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 10)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJYRvO5zRLy2"
      },
      "source": [
        "Sometimes it's useful to have an integer-based arange for indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWooDShhRLy2",
        "outputId": "c1a4b98f-a1fc-4cbd-d427-1748ba014e7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 10).long()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPikPfdURLy2"
      },
      "source": [
        "## Linear Operations\n",
        "\n",
        "Using the tensors to do linear algebra is a foundation of modern Deep Learning practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWnZofmQRLy2"
      },
      "source": [
        "Reshaping allows you to move the numbers in a tensor around.  One can be sure that the order is preserved.  In PyTorch, reshaping is called `view`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lQ8Q7JHRLy2",
        "outputId": "f82c2513-8521-4d55-e218-4c42f9105d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([20])\n",
            "Values: \n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "        18, 19])\n",
            "\n",
            "\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19]])\n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19]])\n",
            "tensor([[ 0],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [ 6],\n",
            "        [ 7],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [11],\n",
            "        [12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 20)\n",
        "describe(x)\n",
        "print(\"\\n\")\n",
        "print(x.view(1, 20))\n",
        "print(x.view(2, 10))\n",
        "print(x.view(4, 5))\n",
        "print(x.view(5, 4))\n",
        "print(x.view(10, 2))\n",
        "print(x.view(20, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzEz5WmQRLy2"
      },
      "source": [
        "Computation between different dimensions.\n",
        "\n",
        "$X(3 × 4) + Y(1 \\times 4)$ and $X(3 × 4) + Z(3 \\times 1)$ are both legitimate operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUeeIrDBRLy2",
        "outputId": "eb93cf16-6ae3-43a0-a95b-7228c26f7aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[0, 1, 2, 3]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 4,  6,  8, 10],\n",
            "        [ 8, 10, 12, 14]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [10, 11, 12, 13]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "y = torch.arange(4).view(1, 4)\n",
        "z = torch.arange(3).view(3, 1)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(x + y)\n",
        "print(x + z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQuGRp0dRLy2"
      },
      "source": [
        "Unsqueeze and squeeze will add and remove 1-dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7KpSMAwRLy2",
        "outputId": "4f8e9bc9-1a35-4f6d-8074-9cdb6964b00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "--\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 1, 4])\n",
            "Values: \n",
            "tensor([[[ 0,  1,  2,  3]],\n",
            "\n",
            "        [[ 4,  5,  6,  7]],\n",
            "\n",
            "        [[ 8,  9, 10, 11]]])\n",
            "--\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "describe(x)\n",
        "print(\"--\")\n",
        "x = x.unsqueeze(dim=1)\n",
        "describe(x)\n",
        "print(\"--\")\n",
        "x = x.squeeze()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyJYCo6mRLy3"
      },
      "source": [
        "The convention of `_` indicating in-place operations continues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXqPMVqRLy3",
        "outputId": "0297e156-79c8-4bc0-e19d-a0aa326801fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "--\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 8, 10, 12, 14],\n",
            "        [16, 18, 20, 22]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(x)\n",
        "print(\"--\")\n",
        "print(x.add_(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehUml6SbRLy3"
      },
      "source": [
        "There are many operations for which reduce a dimension.  Such as sum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIL18iMeRLy3",
        "outputId": "51a6df7e-4a95-48d3-f353-feac96be7199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "Summing across rows (dim=0): \n",
            " tensor([12, 15, 18, 21])\n",
            "---\n",
            "Summing across columns (dim=1): \n",
            " tensor([ 6, 22, 38])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"Summing across rows (dim=0): \\n\", x.sum(dim=0))\n",
        "print(\"---\")\n",
        "print(\"Summing across columns (dim=1): \\n\", x.sum(dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtbH_rRvRLy3"
      },
      "source": [
        "#### Indexing, Slicing, Joining and Mutating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Fuc4CmRLy3",
        "outputId": "9776550b-4a82-441e-a071-bda95c379c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "---\n",
            "x[:2, :2]: \n",
            " tensor([[0, 1],\n",
            "        [3, 4]])\n",
            "---\n",
            "x[0][1]: \n",
            " tensor(1)\n",
            "---\n",
            "Setting [0][1] to be 8\n",
            "tensor([[0, 8, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2, 3)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"x[:2, :2]: \\n\", x[:2, :2])\n",
        "print(\"---\")\n",
        "print(\"x[0][1]: \\n\", x[0][1])\n",
        "print(\"---\")\n",
        "print(\"Setting [0][1] to be 8\")\n",
        "x[0][1] = 8\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74B-xn-RLy4"
      },
      "source": [
        "We can select a subset of a tensor using the `index_select`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH7w1dTjRLy4",
        "outputId": "17a61069-f1b5-4333-fbca-7569c843b3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "print(x)\n",
        "\n",
        "print(\"---\")\n",
        "indices = torch.LongTensor([0, 2])\n",
        "print(torch.index_select(x, dim=0, index=indices))\n",
        "\n",
        "print(\"---\")\n",
        "indices = torch.LongTensor([0, 2])\n",
        "print(torch.index_select(x, dim=1, index=indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eyDEghFRLy4"
      },
      "source": [
        "We can also use numpy-style advanced indexing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Aq9htqhRLy4",
        "outputId": "d6cdb7da-4056-480b-b8e3-f123efd93eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "indices = torch.LongTensor([0, 2])\n",
        "\n",
        "print(x[indices])\n",
        "print(\"---\")\n",
        "print(x[indices, :])\n",
        "print(\"---\")\n",
        "print(x[:, indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHYOoYmPRLy4"
      },
      "source": [
        "We can combine tensors by concatenating them.  First, concatenating on the rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDH2qevURLy4",
        "outputId": "b1f1019b-edbf-470a-cff3-b8c5f82e901d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2,3)\n",
        "describe(x)\n",
        "describe(torch.cat([x, x], dim=0))\n",
        "describe(torch.cat([x, x], dim=1))\n",
        "describe(torch.stack([x, x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHUinVosRLy4"
      },
      "source": [
        "We can concentate along the first dimension.. the columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2-2CTVHRLy4",
        "outputId": "9620bbb3-6fe2-4188-a909-99c94d8fa8b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 9])\n",
            "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
            "        [6, 7, 8, 6, 7, 8, 6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "\n",
        "print(x)\n",
        "print(\"---\")\n",
        "new_x = torch.cat([x, x, x], dim=1)\n",
        "print(new_x.shape)\n",
        "print(new_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRtrRZ0lRLy4"
      },
      "source": [
        "We can also concatenate on a new 0th dimension to \"stack\" the tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lICjI-f_RLy5",
        "outputId": "883c0908-85d2-447f-a2b7-e02967ac138e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 3, 3])\n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "print(x)\n",
        "print(\"---\")\n",
        "new_x = torch.stack([x, x, x])\n",
        "print(new_x.shape)\n",
        "print(new_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_FmoSrDRLy5"
      },
      "source": [
        "#### Linear Algebra Tensor Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByZxRnLFRLy5"
      },
      "source": [
        "Transposing allows you to switch the dimensions to be on different axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "879G_OgNRLy5",
        "outputId": "8bec37e1-617e-41a7-8a7f-c21b2de977b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "x.tranpose(1, 0): \n",
            " tensor([[ 0,  4,  8],\n",
            "        [ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 12).view(3,4)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"x.tranpose(1, 0): \\n\", x.transpose(1, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fzpCe-RLy5"
      },
      "source": [
        "A three dimensional tensor would represent a batch of sequences, where each sequence item has a feature vector.  It is common to switch the batch and sequence dimensions so that we can more easily index the sequence in a sequential model.\n",
        "\n",
        "For example, a training batch consists of 3 sentences with each sentence having 2 words, and each words being represented by 5 features. That is,\n",
        "\n",
        "`batch_size = 3,\n",
        "seq_size = 2,\n",
        "feature_size = 5`\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/static/guide/images/tensor/index1.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75SvyLGxRLy5",
        "outputId": "67f78cb9-be0e-40a7-b113-c60ebec5824c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: \n",
            " torch.Size([3, 2, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29]]])\n",
            "-----\n",
            "x.transpose(1, 0).shape: \n",
            " torch.Size([2, 3, 5])\n",
            "x.transpose(1, 0): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [20, 21, 22, 23, 24]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [15, 16, 17, 18, 19],\n",
            "         [25, 26, 27, 28, 29]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "seq_size = 2\n",
        "feature_size = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
        "\n",
        "print(\"x.shape: \\n\", x.shape)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "\n",
        "print(\"x.transpose(1, 0).shape: \\n\", x.transpose(1, 0).shape)\n",
        "print(\"x.transpose(1, 0): \\n\", x.transpose(1, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permute transpose more than 2 dimensions."
      ],
      "metadata": {
        "id": "sA4HiwxRU2-W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1m2zhmxRLy5",
        "outputId": "a20f68f8-74d0-4a31-cbe9-4f748ebf0a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: \n",
            " torch.Size([3, 2, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29]]])\n",
            "-----\n",
            "x.permute(1, 0, 2).shape: \n",
            " torch.Size([2, 3, 5])\n",
            "x.permute(1, 0, 2): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [20, 21, 22, 23, 24]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [15, 16, 17, 18, 19],\n",
            "         [25, 26, 27, 28, 29]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "seq_size = 2\n",
        "feature_size = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
        "\n",
        "print(\"x.shape: \\n\", x.shape)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "\n",
        "print(\"x.permute(1, 0, 2).shape: \\n\", x.permute(1, 0, 2).shape)\n",
        "print(\"x.permute(1, 0, 2): \\n\", x.permute(1, 0, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqoxuJi0RLy5"
      },
      "source": [
        "Matrix multiplication is `mm`. When multiplying two matrix, the first one's number of columns match the second one's number of rows. For example,\n",
        "\n",
        "$X1(2 \\times 3) · X2(3 \\times 5)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeKNwwjgRLy6",
        "outputId": "ee8910d0-3c7d-49a5-b651-63870340f41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n",
            "---\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 5])\n",
            "Values: \n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]])\n",
            "---\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 5])\n",
            "Values: \n",
            "tensor([[1., 2., 1., 1., 1.],\n",
            "        [1., 2., 1., 1., 1.],\n",
            "        [1., 2., 1., 1., 1.]])\n",
            "---\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 5])\n",
            "Values: \n",
            "tensor([[ 3.,  6.,  3.,  3.,  3.],\n",
            "        [12., 24., 12., 12., 12.]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.arange(6).view(2, 3).float()\n",
        "describe(x1)\n",
        "print(\"---\")\n",
        "\n",
        "x2 = torch.ones(3, 5).float()\n",
        "describe(x2)\n",
        "print(\"---\")\n",
        "\n",
        "x2[:, 1] += 1\n",
        "describe(x2)\n",
        "print(\"---\")\n",
        "\n",
        "describe(torch.mm(x1, x2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QlIyeyHRLy7"
      },
      "source": [
        "See the [PyTorch Math Operations Documentation](https://pytorch.org/docs/stable/torch.html#math-operations) for more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ghMOPZrRLy7"
      },
      "source": [
        "## Computing Gradients\n",
        "\n",
        "The neural network takes training data and keeps updating parameter values for each neuron's computation in the computation graph.\n",
        "\n",
        "For example, when training a neuron function $y=A \\times X + b$, we can use 10 samples, or 10 pairs of $(X, y)$. Initially $A$ is created as a tiny matrix with 0.000001 and $b$ is a tiny vector of 0.000001. After the 1st sample, A will be improved by **gradient** to be a matrix of a new value, $0.000001 + gradient= 0.000015$. b is also to be a vector of $0.000001 + gradient= 0.000015$.\n",
        "\n",
        "After 10 samples, training would update A to be a final matrix of $0.000045$ and b to be the final vector of $0.000045$.\n",
        "\n",
        "In the inference stage, to use the neuron, for any new sample $X$, we can compute the predicted $y$ using $y = 0.000045 \\times X + 0.000045$. The $A$ and $b$ came from many gradient updates through each training sample.\n",
        "\n",
        "> We use uppercased letters A and X, since they represent matrix. $y$ and $b$ usually are vectors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iframe = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nJyUyKN-XBQ?si=ZSuVgL4AkZ6y27ko\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>'\n",
        "display.display(HTML(iframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "B6o2tRxfbQpH",
        "outputId": "924da875-1360-44a5-cca0-d5d2c9476fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/nJyUyKN-XBQ?si=ZSuVgL4AkZ6y27ko\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex.**  Suppose $y=x^2$, in this case, gradient is $dy=2x$. Use `backward` to calculate gradient as below,"
      ],
      "metadata": {
        "id": "NoF2rUc8j7U-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cNgjJlJRLy7",
        "outputId": "4ef20bee-7363-4c85-8ca3-fd8f19423387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The gradient of y = x^2 at x = 2 is: tensor([6.])\n"
          ]
        }
      ],
      "source": [
        "# Set up a tensor by turning on gradient calculation on it.\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "\n",
        "y = x ** 2\n",
        "\n",
        "# Compute the gradient of y with respect to x\n",
        "y.backward()\n",
        "\n",
        "# Print the gradient; dy/dx = 2 * x\n",
        "print(\"The gradient of y = x^2 at x = 2 is:\", x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6tMYa7RLy7"
      },
      "source": [
        "**Ex.** Find the gradient of $f(x)$ at $x=1$,\n",
        "\n",
        "$$f(x)=\\left\\{\n",
        "\\begin{array}{ll}\n",
        "    sin(x) \\text{ if } x>0 \\\\\n",
        "    cos(x) \\text{ otherwise } \\\\\n",
        "\\end{array}\n",
        "\\right.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTcvraa-RLy7"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    if (x.data > 0).all():\n",
        "        return torch.sin(x)\n",
        "    else:\n",
        "        return torch.cos(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nYNMxhkRLy8",
        "outputId": "66f6847e-bffe-4a0c-de66-16c89bea94a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  tensor([1.], requires_grad=True)\n",
            "y:  tensor([0.8415], grad_fn=<SinBackward0>)\n",
            "---\n",
            "tensor([0.5403])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = f(x)\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "print('---')\n",
        "\n",
        "y.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6WM3OsRLy8"
      },
      "source": [
        "We could apply this to a larger vector too, but we need to make sure the output is a scalar. The example below has an error, you need to fix it before running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvHlMlAMRLy8"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
        "y = f(x)\n",
        "print('x: ', x)\n",
        "print('y: ', y)\n",
        "print('---')\n",
        "\n",
        "# this is meant to break! can you fix it??\n",
        "y.backward()\n",
        "\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi_CJGK_RLy8"
      },
      "source": [
        "Solution: making the output `y` a scalar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDhVdXNcRLy9"
      },
      "outputs": [],
      "source": [
        "def describe_grad(x):\n",
        "    if x.grad is None:\n",
        "        print(\"No gradient information\")\n",
        "    else:\n",
        "        print(\"Gradient: \\n{}\".format(x.grad))\n",
        "        print(\"Gradient Function: {}\".format(x.grad_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ublEFtVRLy9",
        "outputId": "01561df6-8c83-4b3e-a0f6-d51c7f2230fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "No gradient information\n",
            "--------\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[21., 21.],\n",
            "        [21., 21.]], grad_fn=<AddBackward0>)\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "21.0\n",
            "No gradient information\n",
            "--------\n",
            "Gradient: \n",
            "tensor([[2.2500, 2.2500],\n",
            "        [2.2500, 2.2500]], grad_fn=<CopyBackwards>)\n",
            "Gradient Function: None\n",
            "--------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1203.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "describe(x)\n",
        "describe_grad(x)\n",
        "print(\"--------\")\n",
        "\n",
        "y = (x + 2) * (x + 5) + 3\n",
        "describe(y)\n",
        "z = y.mean()\n",
        "describe(z)\n",
        "describe_grad(x)\n",
        "print(\"--------\")\n",
        "\n",
        "z.backward(create_graph=True)\n",
        "describe_grad(x)\n",
        "print(\"--------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient function"
      ],
      "metadata": {
        "id": "jXX0j1Y0ogdn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpA1ybKRLy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36c7e2a-923f-4146-9bc6-0b8f8b3f1485"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7aeeb323bc40>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "y = x + 2\n",
        "y.grad_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlc3VZDWRLy9"
      },
      "source": [
        "### CUDA Tensors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iframe = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pPStdjuYzSI?si=amQKbW4j0eiPBv6H\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>'\n",
        "display.display(HTML(iframe))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "-o_pX8ANr2bH",
        "outputId": "d92d70bf-39b7-4021-961c-84a9eac99615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/pPStdjuYzSI?si=amQKbW4j0eiPBv6H\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxVB9bfRLy9"
      },
      "source": [
        "PyTorch's operations can seamlessly be used on the GPU or on the CPU.  There are a couple basic operations for interacting in this way. From here, you will need to enable CUDA either from your Windows or from Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2aunVbTRLy9",
        "outputId": "0255fa4a-f446-431f-d645-6b60a8b8d472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHAJ80gvRLy9",
        "outputId": "50621b07-010f-451f-bed1-180d36dd8e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[0.9665, 0.7399, 0.4517],\n",
            "        [0.4757, 0.7842, 0.1525],\n",
            "        [0.6662, 0.3343, 0.7893]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(3,3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSVTlDYCRLy-",
        "outputId": "5d607dd7-8955-4a7a-cb73-9e9b6b3a857b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WofZ1MZeRLy-",
        "outputId": "35f7b06d-7b06-4740-de5b-ed905e404927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.cuda.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[0.3216, 0.5247, 0.6688],\n",
            "        [0.8436, 0.4265, 0.9561],\n",
            "        [0.0770, 0.4108, 0.0014]], device='cuda:0')\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(3, 3).to(device)\n",
        "describe(x)\n",
        "print(x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeUeJNTARLy-"
      },
      "outputs": [],
      "source": [
        "cpu_device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSFmY-RSRLy-"
      },
      "outputs": [],
      "source": [
        "# this will break!\n",
        "y = torch.rand(3, 3)\n",
        "\n",
        "print(x.device)\n",
        "print(y.device)\n",
        "\n",
        "# This will break and fix it.\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VDEzuwwRLy-",
        "outputId": "87dec929-11ae-4d1c-8559-4c7f82c7c69e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8631, 1.1666, 0.9664],\n",
              "        [1.5513, 0.8455, 1.0217],\n",
              "        [0.9608, 1.2191, 0.7542]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "y = y.to(cpu_device)\n",
        "x = x.to(cpu_device)\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJyZiY7tRLy-"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available(): # only is GPU is available\n",
        "    a = torch.rand(3,3).to(device='cuda:0') #  CUDA Tensor\n",
        "    print(a)\n",
        "\n",
        "    b = torch.rand(3,3).cuda()\n",
        "    print(b)\n",
        "\n",
        "    print(a + b)\n",
        "\n",
        "    # Error expected, need to fix it.\n",
        "    a = a.cpu()\n",
        "\n",
        "    print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-pURLg7RRLy-"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "Some of these exercises require operations not covered in the notebook.  You will have to look at [the documentation](https://pytorch.org/docs/) (on purpose!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnwm1XuBRLy-"
      },
      "source": [
        "#### Exercise 1\n",
        "\n",
        "Create a 2D tensor `t` (3x3) and then add a dimension of size 1 inserted at the 0th axis to reshape to (1x3x3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G6vv75TRLy-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wCBZyfI6RLzB"
      },
      "source": [
        "#### Exercise 2\n",
        "\n",
        "Remove the extra dimension you just added to the previous tensor `t` of a dimension (3x3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1673yA4RLzB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FBYfr0NnRLzB"
      },
      "source": [
        "#### Exercise 4\n",
        "\n",
        "Create a tensor t with dimension (3x3), and values from a normal distribution (mean=0, std=1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLLLRja7RLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVzIGM3URLzC"
      },
      "source": [
        "#### Exercise 5\n",
        "\n",
        "Retrieve the indexes of all the non zero elements in `tensor=([1, 1, 1, 0, 1])`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn7b4a2aRLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5fzBlM9RLzC"
      },
      "source": [
        "#### Exercise 6\n",
        "\n",
        "Create a random tensor of size (3,1) and then horizonally stack 4 copies together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY4Fol_ORLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzDKzqJjRLzC"
      },
      "source": [
        "#### Exercise 7\n",
        "\n",
        "Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)). You can think of the first dimension of a and b is batch_size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz-wZ6eQRLzC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pcrfboKgRLzC"
      },
      "source": [
        "#### Exercise 8\n",
        "\n",
        "Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)). b can be taken as one batch of a matrix data with dimension(5x4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pvsg4iiRLzC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}