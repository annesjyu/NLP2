{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMX2Hdr5XhF8JOhfeUA0zut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annesjyu/NLP2/blob/main/03_NLP2_CNN_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutioal Neural Networks (CNNs) for Language Modeling\n",
        "\n",
        "CNNs is another type of feed-forward NN suitable for language modeling. Feed-forward means moving data forward through network without any backward loops. The core part of CNN applies convolution operations over the sequence text data and identify their in-between complex relationships. It comes from signal processing to use convolution kernels to identify singal patterns.\n",
        "\n",
        "For example, applying a convolution kernel of size=3 to a text sequence, \"this movie has amazing diverse characters\", a new feature vectors will be generated to represent orginal text and its underlying token relationships.\n",
        "\n",
        "<img src=\"https://github.com/annesjyu/NLP2/blob/main/images/conv_maxpooling_steps.gif?raw=true\" width=350></img>\n",
        "\n",
        "* The height of the kernel (e.g. size=3) will be the number of embeddings it will see at once, similar to representing an n-gram in a word model.\n",
        "\n",
        "* The width of the kernel should span the length of an entire word embedding."
      ],
      "metadata": {
        "id": "r3lFUWqNU8Jv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Hyperparameters\n",
        "\n",
        "A few hyperparameters affect the performance of a CNN archiecture. Some concepts are introduced before explaining hyperparameters,\n",
        "\n",
        "* Kernel\n",
        "\n",
        "> It is a small matrix applied at different positions in the input text sequence to compute convolutional result. It is controlled by the `kernel_size`, equal to the kernel's height; and the stepping positions ,e.g. `stride`, the convolution will multiply in the input dataset.\n",
        "\n",
        "* Padding\n",
        "\n",
        "> To conduct convolution operation at the border tokens, padding is used to ensure they have enough length for kernel_size. padding is defined to control the value used for filling missing parts of such tokens.\n",
        "\n",
        "<img src=\"https://github.com/annesjyu/NLP2/blob/main/images/cnn_hyperparameters.gif?raw=true\" width=350></img>\n",
        "\n",
        "* Channels\n",
        "\n",
        "> They mean the feature dimension along each point in the input. In the language modeling, it equals to the size the vocabulary.\n",
        "\n",
        "* Dimensions\n",
        "\n",
        "> The 1D convolutions are useful for time series in which each time step has has a feature vector. Most NLP are 1D convolutions as well.\n",
        "\n",
        "> The 2D convolutions can be used for images with width and height two axis.\n",
        "\n",
        "> The 3D convolutions can be used for videos.\n",
        "\n",
        "* Dilation\n",
        "\n",
        "It's the value in the kernel controls how the convolutional kernel is applied to the input matrix.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g_4BMFSkZV6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation\n",
        "\n",
        "We create a simple synthetic example to introduce immplementation."
      ],
      "metadata": {
        "id": "SJY-eLMXfBrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "vSPruIfQXQd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self, one_hot_size, kernel_size, stride, output_size):\n",
        "    super(SimpleCNN, self).__init__()\n",
        "    self.one_hot_size = one_hot_size\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.output_size = output_size\n",
        "    self.conv1 = nn.Conv1d(in_channels=self.one_hot_size,\n",
        "                  out_channels=16,\n",
        "                  kernel_size=self.kernel_size,\n",
        "                  stride=self.stride)\n",
        "    self.conv2 = nn.Conv1d(in_channels=16,\n",
        "                  out_channels=32,\n",
        "                  kernel_size=self.kernel_size,\n",
        "                  stride=self.stride)\n",
        "    self.conv3 = nn.Conv1d(in_channels=32,\n",
        "                  out_channels=self.output_size,\n",
        "                  kernel_size=self.kernel_size,\n",
        "                  stride=self.stride)\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "      x : the input with a dimension of (batch_size, sequence_width, one_hot_size)\n",
        "      y : the output with a dimension of (batch_size, output_size)\n",
        "    '''\n",
        "    intermediate1 = self.conv1(x)\n",
        "    intermediate2 = self.conv2(intermediate1)\n",
        "    intermediate3 = self.conv3(intermediate2)\n",
        "    #print(x.shape)\n",
        "    #print(intermediate1.shape)\n",
        "    #print(intermediate2.shape)\n",
        "    #print(intermediate3.shape)\n",
        "    y = intermediate3.squeeze()\n",
        "    return y"
      ],
      "metadata": {
        "id": "S4OGLC1ZWOd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation diagram is as below. Pay attention to the dimensions, as if they are matched for matrix multiplications between input data and conv(1,2,3):\n",
        "\n",
        "```\n",
        "sequence_width, one_hot_size, in_channels, out_channels(1,2,3), output_size.\n",
        "```\n",
        "\n",
        "<img src=\"https://github.com/annesjyu/NLP2/blob/main/images/cnn_dims.drawio.png?raw=true\" width=500></img>\n",
        "\n",
        "The channel dimensions are increased because the channel dimension is the feature vector size. The input data has as size of one_hot_size=10, while the output data has a size of output_size=64. In the intermediate layers, feature size is gradually increased to match larger output_size."
      ],
      "metadata": {
        "id": "DPNBhCHaYovW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the simple CNN"
      ],
      "metadata": {
        "id": "FfhqgVMxPV9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import randn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "c_pnIewEr4am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_size = 64\n",
        "one_hot_size = 10\n",
        "\n",
        "model1 = SimpleCNN(one_hot_size=one_hot_size,\n",
        "                   kernel_size=3,\n",
        "                   stride=1,\n",
        "                   output_size=output_size)\n",
        "print(model1)"
      ],
      "metadata": {
        "id": "J1IG9FXO-Kty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def TrainRandn(model,\n",
        "               n_epochs=5,\n",
        "               n_batches=128,\n",
        "               batch_size=3,\n",
        "               sequence_width=7,\n",
        "               output_size=64):\n",
        "  '''\n",
        "    Train the model with the given parameters using randomly generated data.\n",
        "  '''\n",
        "  loss_fn = nn.MSELoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch in range(n_batches):\n",
        "        # Generate fake data for the batch.\n",
        "        x = torch.randn(batch_size, one_hot_size, sequence_width)\n",
        "        y_target = torch.randn(batch_size, output_size)\n",
        "        #print(f'x={x}')\n",
        "        #print(f'y_target={y_target}')\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute predicted y by passing x to the model.\n",
        "        y_pred = model(x)\n",
        "        #print(f'y_pred={y_pred}')\n",
        "        #print(f'y_pred.shape={y_pred.shape}')\n",
        "        #print(f'y_target.shape={y_target.shape}')\n",
        "\n",
        "        # Compute and print loss.\n",
        "        loss = loss_fn(y_pred, y_target)\n",
        "        batch_loss = loss.item()/batch_size\n",
        "        epoch_loss += batch_loss\n",
        "\n",
        "        # Propagate the loss value backward.\n",
        "        loss.backward()\n",
        "\n",
        "        # Trigger the optimizer to update once.\n",
        "        optimizer.step()\n",
        "        # End of one epoch\n",
        "\n",
        "    epoch_loss /= n_batches\n",
        "    print(f'epoch={epoch}, epoch_loss={epoch_loss}\\n')"
      ],
      "metadata": {
        "id": "wAI_3PVZ-x-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainRandn(model1)"
      ],
      "metadata": {
        "id": "_gRwZ8S_eeio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Optimization\n",
        "\n",
        "On the top of `SimpleCNN`, a few optimization techniques can be used to improve its performance."
      ],
      "metadata": {
        "id": "pkdQo4oNMjm5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nonlinearity\n",
        "\n",
        "Nonlinearlity is introduced to model complex non-linear relationship among data. The `Sequential` module is a convenience wrapper to encapsulate a sequence of operations. `ELU` is a nonlinearlity similar to `ReLU` to exponentiate value below 0."
      ],
      "metadata": {
        "id": "6vaUqOHAMwbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "sQt9TtkSO9xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OptCNN(nn.Module):\n",
        "  def __init__(self, one_hot_size, kernel_size, stride, num_classes):\n",
        "    super(OptCNN, self).__init__()\n",
        "    self.one_hot_size = one_hot_size\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.output_size = 64\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    self.convnet = nn.Sequential(\n",
        "        nn.Conv1d(in_channels=self.one_hot_size,\n",
        "                  out_channels=16,\n",
        "                  kernel_size=self.kernel_size,\n",
        "                  stride=self.stride),\n",
        "        nn.ELU(),\n",
        "        nn.Conv1d(in_channels=16,\n",
        "                  out_channels=32,\n",
        "                  kernel_size=self.kernel_size,\n",
        "                  stride=self.stride),\n",
        "        nn.ELU(),\n",
        "        nn.Conv1d(in_channels=32,\n",
        "                  out_channels=self.output_size,\n",
        "                  kernel_size=self.kernel_size,\n",
        "                  stride=self.stride),\n",
        "        nn.ELU()\n",
        "    )\n",
        "    self.fc = nn.Linear(self.output_size, self.num_classes)\n",
        "\n",
        "  def forward(self, x, apply_softmax=False):\n",
        "    '''\n",
        "      x : the input with a dimension of (batch_size, sequence_width, one_hot_size)\n",
        "      y : the output with a dimension of (batch_size, output_size)\n",
        "    '''\n",
        "    features = self.convnet(x).squeeze()\n",
        "    #print(features.shape)\n",
        "    y = self.fc(features)\n",
        "    if apply_softmax:\n",
        "      y = F.softmax(y, dim=1)\n",
        "    return y"
      ],
      "metadata": {
        "id": "ushqUz09M8M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to `Training the simple CNN` section to re-train using the `OptCNN`."
      ],
      "metadata": {
        "id": "MQxUDn_zPPN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of generating a feature vector (64x1) , classify to multiple classes.\n",
        "num_classes = 3\n",
        "model = OptCNN(one_hot_size=one_hot_size,\n",
        "               kernel_size=3,\n",
        "               stride=1,\n",
        "               num_classes=num_classes)\n",
        "TrainRandn(model, output_size=num_classes)"
      ],
      "metadata": {
        "id": "70SjlQ-aiCnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pooling\n",
        "\n",
        "Pooling is an operation to summarize a higher-dimensional feature vector to a lower-dimensional feature vector. The values in the output feature vector summarize a spatial region of input. The summarization can be applied as sum pooling, average pooling, and max pooling. Or you can say pooling transform a weak input feature vector to a statistically strong feature vector.\n",
        "\n",
        "<img src=\"https://github.com/annesjyu/NLP2/blob/main/images/pooling.jpg?raw=true\" width=350></img>"
      ],
      "metadata": {
        "id": "m-X8oUxMP2c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a max pooling layer\n",
        "max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "# Example tensor (e.g., a feature map from a convolutional layer)\n",
        "# Shape: [batch_size, channels, height, width]\n",
        "input_tensor = torch.randn(1, 1, 4, 4)\n",
        "\n",
        "# Apply max pooling\n",
        "output = max_pool(input_tensor)\n",
        "\n",
        "print(\"Input Tensor:\\n\", input_tensor)\n",
        "print(\"Output Tensor:\\n\", output)"
      ],
      "metadata": {
        "id": "fzCj57LJRlTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch Normalization\n",
        "\n",
        "It is commonly used to rescale outputs to have a zero-mean and unit variance. In this case, fluctuatinos in any batch won't affect or shift too much. In statistics, it's called Z-score."
      ],
      "metadata": {
        "id": "OagisfTlRZHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of using nn.Conv1d, use nn.BatchNorm1d\n",
        "# Can you re-write OptCNN to include max pooling and normalization?\n"
      ],
      "metadata": {
        "id": "XND_m-iNx3LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Residual Connections / Residual Block\n",
        "\n",
        "Residual connection is also called skip connection, to take input as part of the output instead of going through computation. It is used for deep neural network architecture, for example, up to 152 layers trainable.\n",
        "\n",
        "A residual network adds a shortcut connection, as shown in subfigure B below. The addition operation is an element-wise addition. This could be written as:\n",
        "$F(x)=ReLU(conv(x) + x)$.\n",
        "\n",
        "<img src=\"https://github.com/annesjyu/NLP2/blob/main/images/residual_connection.png?raw=true\" width=350></img>\n",
        "\n",
        "When implement in CNN, let one layer with a $kernel\\_size = 3$ and $padding = 1$. The output will have the same size of its input."
      ],
      "metadata": {
        "id": "v7Wn6vTayLaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Can you add a residual connection layer to the conv3 in the previous OptCNN?\n"
      ],
      "metadata": {
        "id": "Kh6exIBsRTtd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}