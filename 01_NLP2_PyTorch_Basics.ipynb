{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annesjyu/NLP2/blob/main/01_NLP2_PyTorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y18okPMJRLyt"
      },
      "source": [
        "# PyTorch Basics\n",
        "\n",
        "PyTorch is a leading deep learning framework that provides extensive libraries to develop complex Neural Network architectures. NLP has greatly benefited from deep learning techniques, especially in areas like language modeling,\n",
        "\n",
        "## Learning objectives\n",
        "\n",
        "* Computational Graphs\n",
        "* Tensors\n",
        "* Operations with tensors\n",
        "* Indexing, slicing, and joining\n",
        "* Computing gradients\n",
        "* Use CUDA tensors with GPUs\n",
        "\n",
        "## Important Prerequisite Terms\n",
        "\n",
        "1.   features\n",
        "2.   targets\n",
        "3.   models\n",
        "4.   parameters\n",
        "5.   hyperparameters\n",
        "6.   predictions\n",
        "7.   loss functions\n",
        "8.   learning/training\n",
        "9.   testing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computational Graph\n",
        "\n",
        "A computational graph is a fundamental concept that underpins how neural networks are constructed and executed.\n",
        "\n",
        "1. Node\n",
        "\n",
        "> Node represents either a **variable** (like input data, weights, biases) or an operation (like mathematical operations, activation functions). The edges of the graph represent the flow of data from one node to another.\n",
        "\n",
        "2. Backpropagation and Autograd\n",
        "\n",
        "> PyTorch is the autograd system. When performing backpropagation for training neural networks, gradients are computed automatically.\n",
        "\n",
        "3. Eager Execution\n",
        "\n",
        "> PyTorch operations are evaluated as they are called, which is different from static graphs used in other frameworks like TensorFlow (prior to version 2.0), where the graph is defined and compiled before it is run. Eager execution makes PyTorch more intuitive and user-friendly, especially for debugging, as it allows for normal Python debugging tools to be used.\n",
        "\n",
        "4. Optimization and GPU Acceleration\n",
        "\n",
        "> Since the graph outlines the entire sequence of operations, PyTorch can optimize memory usage and computation for better performance.\n",
        "\n",
        "Reference:\n",
        "\n",
        "> Vijay. (2023). *Deep Learning: Computational Graphs*. Medium, March 2021. [https://vijay110402.medium.com/deep-learning-computational-graphs-f0e12d82f78d](https://vijay110402.medium.com/deep-learning-computational-graphs-f0e12d82f78d)\n",
        "\n",
        "For example,\n",
        "\n",
        "A computational graph is used to implement a function $f(A,B,C) =(A*B)+C$:\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*HK6gaBlCJLQOTldCURi7qQ.gif\" height=200>\n",
        "\n",
        "A computational graph is used to implement a basic neural network layer:\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*d3uM1IwDZWqvEU2G0p0gxA.gif\" height=200>\n",
        "\n"
      ],
      "metadata": {
        "id": "zRqJHr8PooRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython  import display\n",
        "from IPython.display import IFrame\n",
        "\n",
        "# Display a webpage in an IFrame\n",
        "url = \"https://www.youtube.com/embed/JAB_plj2rbA?si=x7woApkNANHhq9Ow\"\n",
        "iframe = IFrame(url, width=560, height=315)\n",
        "display.display(iframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "g60-3CnemKLk",
        "outputId": "4e945c25-fa45-475d-8e64-62423ef59e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f2664defbb0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"560\"\n",
              "            height=\"315\"\n",
              "            src=\"https://www.youtube.com/embed/JAB_plj2rbA?si=x7woApkNANHhq9Ow\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic (Define-by-Run) Nature\n",
        "\n",
        "### Static Computational Graphs (TensorFlow)\n",
        "\n",
        "A static computational graph means the graph's structure is defined and compiled before it's run. Once compiled, it cannot be changed. This is what TensorFlow used initially (up until v2.0, where it embraced more dynamic graphs through Eager Execution).\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:504/format:webp/0*4UHwQnsmUjyD7VtW.gif\">\n",
        "\n",
        "#### Advantages:\n",
        "\n",
        "* Efficiency: Once compiled, the graph can be optimized, leading to faster execution and less resource consumption.\n",
        "Portability: The graph can be saved, deployed, and run without the code that generated it.\n",
        "\n",
        "* Visualization: Easy to visualize and debug using tools like TensorBoard.\n",
        "\n",
        "#### Disadvantages:\n",
        "* Less Intuitive: Harder for Python programmers to debug and understand, as the code doesn't execute Python line by line.\n",
        "\n",
        "* Flexibility: Less flexible in changing the graph during runtime, making it difficult for dynamic models and research.\n",
        "\n",
        "### Dynamic Computational Graphs (PyTorch)\n",
        "\n",
        "A dynamic computational graph, also known as an \"imperative\" or \"define-by-run\" graph, is constructed on the fly during execution. This approach is used by PyTorch.\n",
        "\n",
        "#### Advantages:\n",
        "\n",
        "* Intuitiveness: More intuitive and pythonic. The graph is built as the code is run, making it easier to understand and debug.\n",
        "\n",
        "* Flexibility: Easy to change and adapt the graph dynamically, which is particularly useful for models where the structure changes every iteration (e.g., with variable input lengths or recursive neural networks).\n",
        "\n",
        "#### Disadvantages:\n",
        "* Overhead: The flexibility can come with a runtime overhead, as the graph needs to be built from scratch at each iteration.\n",
        "\n",
        "* Optimization: Less opportunity for upfront optimization compared to static graphs."
      ],
      "metadata": {
        "id": "LVT-06PnWLwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing PyTorch"
      ],
      "metadata": {
        "id": "kQ_TbumOkWT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JEKsvhVRLyv",
        "outputId": "69632c20-b084-42f4-8a78-ca88a71aceab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f26fae6abf0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrO2Vts_RLyw"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "In PyTorch, a tensor is a fundamental data structure that is similar to an array or a matrix. Tensors are used to encode the inputs and outputs of a model, as well as the modelâ€™s parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5c9p-xRLyw"
      },
      "source": [
        "* Scalar is a single number. Rank 0 tensor.\n",
        "* Vector is an array of numbers - Rank 1 tensor.\n",
        "* Matrix is a 2-D array of numbers - Rank 2 tensor.\n",
        "* Tensors are N-D arrays of numbers - Rank N tensor.\n",
        "\n",
        "### Features\n",
        "\n",
        "* GPU Support\n",
        "\n",
        "> Unlike NumPy arrays, PyTorch tensors can be stored and operated on a Graphics Processing Unit (GPU) to accelerate computing. This is crucial for training deep learning models efficiently.\n",
        "\n",
        "* Automatic Differentiation\n",
        "\n",
        "> PyTorch tensors support automatic differentiation. When tensors are used in neural networks, PyTorch tracks all operations on them. This feature is fundamental for the backpropagation algorithm, as it allows PyTorch to automatically compute gradients.\n",
        "\n",
        "* Interoperability with NumPy\n",
        "\n",
        "> PyTorch tensors can be easily converted to and from NumPy arrays. This allows for leveraging the vast ecosystem of tools and libraries available for NumPy.\n",
        "\n",
        "* Dynamic Computational Graph:\n",
        "\n",
        "> PyTorch uses a dynamic computational graph, which means that the graph is generated on the fly as operations are performed on tensors.\n",
        "\n",
        "* Data Type and Device: Each tensor in\n",
        "\n",
        "> PyTorch has a data type (such as float, int) and a device (such as CPU or GPU) on which it is stored. This allows for control over the precision and computing resources used in calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtTf6U6JRLyw"
      },
      "source": [
        "#### Creating Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VpzmgkFRLyw"
      },
      "source": [
        "You can create tensors by specifying the shape as arguments.  Here is a tensor with 2 rows and 3 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaKoNb2pRLyw"
      },
      "outputs": [],
      "source": [
        "def describe(x):\n",
        "    print(\"Type: {}\".format(x.type()))\n",
        "    print(\"Shape/size: {}\".format(x.shape))\n",
        "    print(\"Values: \\n{}\".format(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tensor from a uniform distribution on the interval $[0,1)$."
      ],
      "metadata": {
        "id": "_MzGUSt6tcb_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR0bSM51RLyw",
        "outputId": "aa983d8c-d73f-4ccd-bcc3-a84236cce80f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[2.7654e+01, 3.2942e-41, 2.2883e+11],\n",
            "        [4.5614e-41, 0.0000e+00, 0.0000e+00]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.Tensor(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a tensor from the standard normal distribution."
      ],
      "metadata": {
        "id": "czyH2fn0tlmw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4vpIjPeRLyw",
        "outputId": "424d614a-a150-40fb-de5c-3920f93f1656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 0.0461,  0.4024, -1.0115],\n",
            "        [ 0.2167, -0.6123,  0.5036]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.randn(2, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CPi-UNURLyx"
      },
      "source": [
        "It's common in prototyping to create a tensor with random numbers of a specific shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGJ21DwrRLyx",
        "outputId": "2d52d405-295c-4242-8681-0945b937a10a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.7749, 0.8208, 0.2793],\n",
            "        [0.6817, 0.2837, 0.6567]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVmo8OajRLyx"
      },
      "source": [
        "You can also initialize tensors of **ones** or **zeros**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKHrU1V2RLyx",
        "outputId": "60db4b0f-ee29-499a-a2d7-f490064d702b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.zeros(2, 3))\n",
        "x = torch.ones(2, 3)\n",
        "describe(x)\n",
        "# Any function with an underscore refers to an in-place operation.\n",
        "x.fill_(5)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjRIGQUsRLyx"
      },
      "source": [
        "Tensors can be initialized and then filled in place.\n",
        "\n",
        "Note: operations that end in an underscore (`_`) are in place operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH7iTY_eRLyy",
        "outputId": "16c054d9-641e-45a6-9748-cf825f67243b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor(3,4).fill_(5)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5Q9-X4DRLyy"
      },
      "source": [
        "Tensors can be initialized from a list of lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpBA-XHMRLyy",
        "outputId": "47d75b96-c6f9-4e60-dfc1-8210f6a1b2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [2., 4.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.Tensor([[1, 2,],\n",
        "                  [2, 4,]])\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVhRwCIRLyy"
      },
      "source": [
        "Tensors can be initialized from numpy matrices. It is important to convert between NumPy arrays and PyTorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owRb0DnqRLyy",
        "outputId": "5448939c-463d-4c6d-bef8-ce16fd1e209a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.DoubleTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.3895, 0.5496, 0.7008],\n",
            "        [0.5033, 0.6361, 0.9503]], dtype=torch.float64)\n",
            "float64\n"
          ]
        }
      ],
      "source": [
        "npy = np.random.rand(2, 3)\n",
        "describe(torch.from_numpy(npy))\n",
        "print(npy.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJKbo270RLyy"
      },
      "source": [
        "#### Tensor Types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnZe9JkcRLyy"
      },
      "source": [
        "The FloatTensor has been the default tensor that we have been creating all along"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOqMMPsyRLyy",
        "outputId": "f9fbbf7d-a2d0-4fb9-c3f9-b03f9352ac38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.arange(6).view(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use contructors - FloatTensor, LongTensor, or use a typecasting method, `dtype`."
      ],
      "metadata": {
        "id": "9idBF6GWv02W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vhR-6mRLyz",
        "outputId": "4a5eb4d8-e13a-4b57-ddc2-4e15e92c8ed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "describe(x)\n",
        "\n",
        "x = x.long()\n",
        "describe(x)\n",
        "\n",
        "x = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6]], dtype=torch.int64)\n",
        "describe(x)\n",
        "\n",
        "x = x.float()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZGywBI_RLyz",
        "outputId": "16ba6325-2fff-4382-8745-2337fda8a4a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 1.5385, -0.9757,  1.5769],\n",
            "        [ 0.3840, -0.6039, -0.5240]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Math Operations"
      ],
      "metadata": {
        "id": "2TmEx8FtgZQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scu7zeivRLyz",
        "outputId": "0065e5a9-7d21-4ac7-994e-058df3aa1589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 3.0771, -1.9515,  3.1539],\n",
            "        [ 0.7680, -1.2077, -1.0479]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[ 3.0771, -1.9515,  3.1539],\n",
            "        [ 0.7680, -1.2077, -1.0479]])\n"
          ]
        }
      ],
      "source": [
        "# plus\n",
        "describe(x + x)\n",
        "# add func\n",
        "describe(torch.add(x, x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Concatenation and Joining"
      ],
      "metadata": {
        "id": "gLpB0EORgjid"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP-gisPgRLyz",
        "outputId": "1dcc3cdb-4d9f-4bcb-d3b5-5ccbf013b133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([6])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EE_sGHzRLyz",
        "outputId": "001c8455-39e8-4f91-d580-93f27cee335b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "# Reshape\n",
        "x = x.view(2, 3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenation\n",
        "describe(torch.cat([x, x], dim=0))\n",
        "describe(torch.cat([x, x], dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZtpYEz5fVQq",
        "outputId": "a5f50314-c326-4ae0-84d6-7635b5dca2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe(torch.stack([x, x], dim=0))\n",
        "describe(torch.stack([x, x], dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcrgS1ZgfoHK",
        "outputId": "fe4b0c89-b625-468d-bfcc-70dc349409c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [0, 1, 2]],\n",
            "\n",
            "        [[3, 4, 5],\n",
            "         [3, 4, 5]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHqoGp5bRLy0",
        "outputId": "c06fb11f-421d-4bcf-9876-33f055596f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3])\n",
            "Values: \n",
            "tensor([3, 5, 7])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([ 3, 12])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.sum(x, dim=0))\n",
        "describe(torch.sum(x, dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQh8MNLzRLy0",
        "outputId": "17fbdad9-ab91-4a5e-a9a5-d8d638e3506d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[0, 3],\n",
            "        [1, 4],\n",
            "        [2, 5]])\n"
          ]
        }
      ],
      "source": [
        "describe(torch.transpose(x, 0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4bAWWjRRLy0",
        "outputId": "cc9f55cd-a5ba-4f80-8142-9600dcb0a433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([1, 2])\n",
            "Values: \n",
            "tensor([[0, 1]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.arange(6).view(2, 3)\n",
        "describe(x)\n",
        "describe(x[:1, :2])\n",
        "describe(x[0, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCAtx77lRLy0",
        "outputId": "d8b159ac-db77-4383-eee9-b457984bd07b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[0, 2],\n",
            "        [3, 5]])\n"
          ]
        }
      ],
      "source": [
        "indices = torch.LongTensor([0, 2])\n",
        "print(indices)\n",
        "describe(torch.index_select(x, dim=1, index=indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UHHRY9eRLy0",
        "outputId": "973191f4-9921-4529-b4c6-7f15244c021c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [0, 1, 2]])\n"
          ]
        }
      ],
      "source": [
        "indices = torch.LongTensor([0, 0])\n",
        "print(indices)\n",
        "describe(torch.index_select(x, dim=0, index=indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw4AOxtiRLy0",
        "outputId": "3036349a-0a98-411a-9301-40ab570f7ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0, 4])\n"
          ]
        }
      ],
      "source": [
        "row_indices = torch.arange(2).long()\n",
        "col_indices = torch.LongTensor([0, 1])\n",
        "describe(x[row_indices, col_indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMB7qOEpRLy0"
      },
      "source": [
        "Long Tensors are used for indexing operations and mirror the `int64` numpy type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO6X4Q96RLy0",
        "outputId": "ae68fe46-af7a-4dda-d066-acf8c1bd4630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "torch.int64\n",
            "int64\n"
          ]
        }
      ],
      "source": [
        "x = torch.LongTensor([[1, 2, 3],\n",
        "                      [4, 5, 6],\n",
        "                      [7, 8, 9]])\n",
        "describe(x)\n",
        "print(x.dtype)\n",
        "print(x.numpy().dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR8c6UsXRLy1"
      },
      "source": [
        "You can convert a FloatTensor to a LongTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85jb9DSyRLy1",
        "outputId": "37747113-fc5b-4d68-c784-3bd640368b4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.FloatTensor([[1, 2, 3],\n",
        "                       [4, 5, 6],\n",
        "                       [7, 8, 9]])\n",
        "x = x.long()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jruGKEGQRLy1"
      },
      "source": [
        "### Special Tensor initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLfQHZHQRLy1"
      },
      "source": [
        "We can create a vector of incremental numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNmuEaGeRLy2",
        "outputId": "514b6002-7406-4992-cf76-ae99ac7d9a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 10)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJYRvO5zRLy2"
      },
      "source": [
        "Sometimes it's useful to have an integer-based arange for indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWooDShhRLy2",
        "outputId": "282f2e33-566b-43ac-e933-dc6fbdf01b58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([10])\n",
            "Values: \n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 10).long()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPikPfdURLy2"
      },
      "source": [
        "## Advanced Matrix Operations\n",
        "\n",
        "Using the tensors to do linear algebra is a foundation of modern Deep Learning practices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWnZofmQRLy2"
      },
      "source": [
        "Reshaping allows you to move the numbers in a tensor around.  One can be sure that the order is preserved.  In PyTorch, reshaping is called `view`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lQ8Q7JHRLy2",
        "outputId": "164ef875-4c30-418d-8831-40db8972c70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "         18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15],\n",
            "        [16, 17, 18, 19]])\n",
            "tensor([[ 0,  1],\n",
            "        [ 2,  3],\n",
            "        [ 4,  5],\n",
            "        [ 6,  7],\n",
            "        [ 8,  9],\n",
            "        [10, 11],\n",
            "        [12, 13],\n",
            "        [14, 15],\n",
            "        [16, 17],\n",
            "        [18, 19]])\n",
            "tensor([[ 0],\n",
            "        [ 1],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [ 6],\n",
            "        [ 7],\n",
            "        [ 8],\n",
            "        [ 9],\n",
            "        [10],\n",
            "        [11],\n",
            "        [12],\n",
            "        [13],\n",
            "        [14],\n",
            "        [15],\n",
            "        [16],\n",
            "        [17],\n",
            "        [18],\n",
            "        [19]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 20)\n",
        "\n",
        "print(x.view(1, 20))\n",
        "print(x.view(2, 10))\n",
        "print(x.view(4, 5))\n",
        "print(x.view(5, 4))\n",
        "print(x.view(10, 2))\n",
        "print(x.view(20, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzEz5WmQRLy2"
      },
      "source": [
        "We can use view to add size-1 dimensions, which can be useful for combining with other tensors.  This is called broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUeeIrDBRLy2",
        "outputId": "14eca460-e949-4bc9-af2f-46c4962fac4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[0, 1, 2, 3]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 4,  6,  8, 10],\n",
            "        [ 8, 10, 12, 14]])\n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [10, 11, 12, 13]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "y = torch.arange(4).view(1, 4)\n",
        "z = torch.arange(3).view(3, 1)\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(x + y)\n",
        "print(x + z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQuGRp0dRLy2"
      },
      "source": [
        "Unsqueeze and squeeze will add and remove 1-dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7KpSMAwRLy2",
        "outputId": "b44a44cc-8e5f-4688-9ed0-ce69e7d8ea72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 1, 4])\n",
            "Values: \n",
            "tensor([[[ 0,  1,  2,  3]],\n",
            "\n",
            "        [[ 4,  5,  6,  7]],\n",
            "\n",
            "        [[ 8,  9, 10, 11]]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "describe(x)\n",
        "\n",
        "x = x.unsqueeze(dim=1)\n",
        "describe(x)\n",
        "\n",
        "x = x.squeeze()\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQiEByYRLy3"
      },
      "source": [
        "all of the standard mathematics operations apply (such as `add` below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPoyMBnLRLy3",
        "outputId": "47918291-0ef0-4299-aa07-93ed24cc33ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[0.6662, 0.3343, 0.7893, 0.3216],\n",
            "        [0.5247, 0.6688, 0.8436, 0.4265],\n",
            "        [0.9561, 0.0770, 0.4108, 0.0014]])\n",
            "--\n",
            "torch.add(x, x): \n",
            " tensor([[1.3324, 0.6686, 1.5786, 0.6433],\n",
            "        [1.0494, 1.3377, 1.6872, 0.8530],\n",
            "        [1.9123, 0.1540, 0.8216, 0.0028]])\n",
            "--\n",
            "x+x: \n",
            " tensor([[1.3324, 0.6686, 1.5786, 0.6433],\n",
            "        [1.0494, 1.3377, 1.6872, 0.8530],\n",
            "        [1.9123, 0.1540, 0.8216, 0.0028]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(3,4)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"--\")\n",
        "print(\"torch.add(x, x): \\n\", torch.add(x, x))\n",
        "print(\"--\")\n",
        "print(\"x+x: \\n\", x + x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyJYCo6mRLy3"
      },
      "source": [
        "The convention of `_` indicating in-place operations continues:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXqPMVqRLy3",
        "outputId": "bb776e44-6da9-4a81-f3f8-072b6b48ce44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "tensor([[ 0,  2,  4,  6],\n",
            "        [ 8, 10, 12, 14],\n",
            "        [16, 18, 20, 22]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(x)\n",
        "print(x.add_(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehUml6SbRLy3"
      },
      "source": [
        "There are many operations for which reduce a dimension.  Such as sum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIL18iMeRLy3",
        "outputId": "6920e02b-69dc-45e7-a963-48197852934f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "Summing across rows (dim=0): \n",
            " tensor([12, 15, 18, 21])\n",
            "---\n",
            "Summing across columns (dim=1): \n",
            " tensor([ 6, 22, 38])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(12).reshape(3, 4)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"Summing across rows (dim=0): \\n\", x.sum(dim=0))\n",
        "print(\"---\")\n",
        "print(\"Summing across columns (dim=1): \\n\", x.sum(dim=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtbH_rRvRLy3"
      },
      "source": [
        "#### Indexing, Slicing, Joining and Mutating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6Fuc4CmRLy3",
        "outputId": "8a4f95c1-a52b-43cb-d455-576eca95a51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "---\n",
            "x[:2, :2]: \n",
            " tensor([[0, 1],\n",
            "        [3, 4]])\n",
            "---\n",
            "x[0][1]: \n",
            " tensor(1)\n",
            "---\n",
            "Setting [0][1] to be 8\n",
            "tensor([[0, 8, 2],\n",
            "        [3, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2, 3)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"x[:2, :2]: \\n\", x[:2, :2])\n",
        "print(\"---\")\n",
        "print(\"x[0][1]: \\n\", x[0][1])\n",
        "print(\"---\")\n",
        "print(\"Setting [0][1] to be 8\")\n",
        "x[0][1] = 8\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74B-xn-RLy4"
      },
      "source": [
        "We can select a subset of a tensor using the `index_select`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH7w1dTjRLy4",
        "outputId": "b74e1bdc-5838-43a0-bf8e-50844fe21cdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "print(x)\n",
        "\n",
        "print(\"---\")\n",
        "indices = torch.LongTensor([0, 2])\n",
        "print(torch.index_select(x, dim=0, index=indices))\n",
        "\n",
        "print(\"---\")\n",
        "indices = torch.LongTensor([0, 2])\n",
        "print(torch.index_select(x, dim=1, index=indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eyDEghFRLy4"
      },
      "source": [
        "We can also use numpy-style advanced indexing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Aq9htqhRLy4",
        "outputId": "8bb05822-056c-45ea-c635-21df37662762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 1, 2],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "tensor([[0, 2],\n",
            "        [3, 5],\n",
            "        [6, 8]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "indices = torch.LongTensor([0, 2])\n",
        "\n",
        "print(x[indices])\n",
        "print(\"---\")\n",
        "print(x[indices, :])\n",
        "print(\"---\")\n",
        "print(x[:, indices])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHYOoYmPRLy4"
      },
      "source": [
        "We can combine tensors by concatenating them.  First, concatenating on the rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDH2qevURLy4",
        "outputId": "59bf24fe-ab01-4b32-c07d-3d5811f4a1b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([4, 3])\n",
            "Values: \n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 6])\n",
            "Values: \n",
            "tensor([[0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5]])\n",
            "Type: torch.LongTensor\n",
            "Shape/size: torch.Size([2, 2, 3])\n",
            "Values: \n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(6).view(2,3)\n",
        "describe(x)\n",
        "describe(torch.cat([x, x], dim=0))\n",
        "describe(torch.cat([x, x], dim=1))\n",
        "describe(torch.stack([x, x]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHUinVosRLy4"
      },
      "source": [
        "We can concentate along the first dimension.. the columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2-2CTVHRLy4",
        "outputId": "16091149-3637-4613-bf25-eb364f60be25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 9])\n",
            "tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],\n",
            "        [3, 4, 5, 3, 4, 5, 3, 4, 5],\n",
            "        [6, 7, 8, 6, 7, 8, 6, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "\n",
        "print(x)\n",
        "print(\"---\")\n",
        "new_x = torch.cat([x, x, x], dim=1)\n",
        "print(new_x.shape)\n",
        "print(new_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRtrRZ0lRLy4"
      },
      "source": [
        "We can also concatenate on a new 0th dimension to \"stack\" the tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lICjI-f_RLy5",
        "outputId": "5a4b575e-63f4-47ad-a58f-c1e0bb530103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "---\n",
            "torch.Size([3, 3, 3])\n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]],\n",
            "\n",
            "        [[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(9).view(3,3)\n",
        "print(x)\n",
        "print(\"---\")\n",
        "new_x = torch.stack([x, x, x])\n",
        "print(new_x.shape)\n",
        "print(new_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_FmoSrDRLy5"
      },
      "source": [
        "#### Linear Algebra Tensor Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByZxRnLFRLy5"
      },
      "source": [
        "Transposing allows you to switch the dimensions to be on different axis. So we can make it so all the rows are columsn and vice versa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "879G_OgNRLy5",
        "outputId": "d0ce2cfc-47d3-436b-8229-609def23b813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11]])\n",
            "---\n",
            "x.tranpose(1, 0): \n",
            " tensor([[ 0,  4,  8],\n",
            "        [ 1,  5,  9],\n",
            "        [ 2,  6, 10],\n",
            "        [ 3,  7, 11]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 12).view(3,4)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "print(\"x.tranpose(1, 0): \\n\", x.transpose(1, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_fzpCe-RLy5"
      },
      "source": [
        "A three dimensional tensor would represent a batch of sequences, where each sequence item has a feature vector.  It is common to switch the batch and sequence dimensions so that we can more easily index the sequence in a sequence model.\n",
        "\n",
        "Note: Transpose will only let you swap 2 axes.  Permute (in the next cell) allows for multiple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75SvyLGxRLy5",
        "outputId": "7415d932-e1ca-4363-da21-91d22df085fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: \n",
            " torch.Size([3, 4, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "-----\n",
            "x.transpose(1, 0).shape: \n",
            " torch.Size([4, 3, 5])\n",
            "x.transpose(1, 0): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [20, 21, 22, 23, 24],\n",
            "         [40, 41, 42, 43, 44]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [45, 46, 47, 48, 49]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [50, 51, 52, 53, 54]],\n",
            "\n",
            "        [[15, 16, 17, 18, 19],\n",
            "         [35, 36, 37, 38, 39],\n",
            "         [55, 56, 57, 58, 59]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "seq_size = 4\n",
        "feature_size = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
        "\n",
        "print(\"x.shape: \\n\", x.shape)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "\n",
        "print(\"x.transpose(1, 0).shape: \\n\", x.transpose(1, 0).shape)\n",
        "print(\"x.transpose(1, 0): \\n\", x.transpose(1, 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4M-LEBNRLy5"
      },
      "source": [
        "Permute is a more general version of tranpose:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1m2zhmxRLy5",
        "outputId": "79ad3be6-2046-4bcd-c3b4-f2498642907d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape: \n",
            " torch.Size([3, 4, 5])\n",
            "x: \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8,  9],\n",
            "         [10, 11, 12, 13, 14],\n",
            "         [15, 16, 17, 18, 19]],\n",
            "\n",
            "        [[20, 21, 22, 23, 24],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [35, 36, 37, 38, 39]],\n",
            "\n",
            "        [[40, 41, 42, 43, 44],\n",
            "         [45, 46, 47, 48, 49],\n",
            "         [50, 51, 52, 53, 54],\n",
            "         [55, 56, 57, 58, 59]]])\n",
            "-----\n",
            "x.permute(1, 0, 2).shape: \n",
            " torch.Size([4, 3, 5])\n",
            "x.permute(1, 0, 2): \n",
            " tensor([[[ 0,  1,  2,  3,  4],\n",
            "         [20, 21, 22, 23, 24],\n",
            "         [40, 41, 42, 43, 44]],\n",
            "\n",
            "        [[ 5,  6,  7,  8,  9],\n",
            "         [25, 26, 27, 28, 29],\n",
            "         [45, 46, 47, 48, 49]],\n",
            "\n",
            "        [[10, 11, 12, 13, 14],\n",
            "         [30, 31, 32, 33, 34],\n",
            "         [50, 51, 52, 53, 54]],\n",
            "\n",
            "        [[15, 16, 17, 18, 19],\n",
            "         [35, 36, 37, 38, 39],\n",
            "         [55, 56, 57, 58, 59]]])\n"
          ]
        }
      ],
      "source": [
        "batch_size = 3\n",
        "seq_size = 4\n",
        "feature_size = 5\n",
        "\n",
        "x = torch.arange(batch_size * seq_size * feature_size).view(batch_size, seq_size, feature_size)\n",
        "\n",
        "print(\"x.shape: \\n\", x.shape)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"-----\")\n",
        "\n",
        "print(\"x.permute(1, 0, 2).shape: \\n\", x.permute(1, 0, 2).shape)\n",
        "print(\"x.permute(1, 0, 2): \\n\", x.permute(1, 0, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqoxuJi0RLy5"
      },
      "source": [
        "Matrix multiplication is `mm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R9oquUgRLy6",
        "outputId": "655bf535-5d2d-4289-ce45-162ce1691bfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4790,  0.8539, -0.2285],\n",
              "        [ 0.3081,  1.1171,  0.1585]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "torch.randn(2, 3, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeKNwwjgRLy6",
        "outputId": "fb055697-0602-45cd-bb9b-5584e237577a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[ 3.,  6.],\n",
            "        [12., 24.]])\n"
          ]
        }
      ],
      "source": [
        "x1 = torch.arange(6).view(2, 3).float()\n",
        "describe(x1)\n",
        "\n",
        "x2 = torch.ones(3, 2)\n",
        "x2[:, 1] += 1\n",
        "describe(x2)\n",
        "\n",
        "describe(torch.mm(x1, x2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUlXTU78RLy7",
        "outputId": "029a931d-7b37-4a7d-e552-4e33e98d0b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.,  1.,  2.,  3.],\n",
            "        [ 4.,  5.,  6.,  7.],\n",
            "        [ 8.,  9., 10., 11.]])\n",
            "tensor([[1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.],\n",
            "        [1., 2.]])\n",
            "tensor([[ 6., 12.],\n",
            "        [22., 44.],\n",
            "        [38., 76.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.arange(0, 12).view(3,4).float()\n",
        "print(x)\n",
        "\n",
        "x2 = torch.ones(4, 2)\n",
        "x2[:, 1] += 1\n",
        "print(x2)\n",
        "\n",
        "print(x.mm(x2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QlIyeyHRLy7"
      },
      "source": [
        "See the [PyTorch Math Operations Documentation](https://pytorch.org/docs/stable/torch.html#math-operations) for more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ghMOPZrRLy7"
      },
      "source": [
        "## Computing Gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87pclYkORLy7",
        "outputId": "b7130c86-a31d-40a3-8d66-b2f693fa109e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 9.]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[2.0, 3.0]], requires_grad=True)\n",
        "z = 3 * x\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8ZV79SVRLy7"
      },
      "source": [
        "In this small snippet, you can see the gradient computations at work.  We create a tensor and multiply it by 3.  Then, we create a scalar output using `sum()`.  A Scalar output is needed as the the loss variable. Then, called backward on the loss means it computes its rate of change with respect to the inputs.  Since the scalar was created with sum, each position in z and x are independent with respect to the loss scalar.\n",
        "\n",
        "The rate of change of x with respect to the output is just the constant 3 that we multiplied x by."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cNgjJlJRLy7",
        "outputId": "d1c74889-f38d-46a8-a9b3-335895903516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            " tensor([[2., 3.]], requires_grad=True)\n",
            "---\n",
            "z = 3*x: \n",
            " tensor([[6., 9.]], grad_fn=<MulBackward0>)\n",
            "---\n",
            "loss = z.sum(): \n",
            " tensor(15., grad_fn=<SumBackward0>)\n",
            "---\n",
            "after loss.backward(), x.grad: \n",
            " tensor([[3., 3.]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[2.0, 3.0]], requires_grad=True)\n",
        "print(\"x: \\n\", x)\n",
        "print(\"---\")\n",
        "z = 3 * x\n",
        "print(\"z = 3*x: \\n\", z)\n",
        "print(\"---\")\n",
        "\n",
        "loss = z.sum()\n",
        "print(\"loss = z.sum(): \\n\", loss)\n",
        "print(\"---\")\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print(\"after loss.backward(), x.grad: \\n\", x.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6tMYa7RLy7"
      },
      "source": [
        "### Example: Computing a conditional gradient\n",
        "\n",
        "$$ \\text{ Find the gradient of f(x) at x=1 } $$\n",
        "$$ {} $$\n",
        "$$ f(x)=\\left\\{\n",
        "\\begin{array}{ll}\n",
        "    sin(x) \\text{ if } x>0 \\\\\n",
        "    cos(x) \\text{ otherwise } \\\\\n",
        "\\end{array}\n",
        "\\right.$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTcvraa-RLy7"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    if (x.data > 0).all():\n",
        "        return torch.sin(x)\n",
        "    else:\n",
        "        return torch.cos(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nYNMxhkRLy8",
        "outputId": "676b5fb9-1e81-4d51-b564-4d47a4b90545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5403])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0], requires_grad=True)\n",
        "y = f(x)\n",
        "y.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6WM3OsRLy8"
      },
      "source": [
        "We could apply this to a larger vector too, but we need to make sure the output is a scalar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "lvHlMlAMRLy8",
        "outputId": "a36aaa25-2167-49e2-c84c-300dfccdbdaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2])\n",
            "Values: \n",
            "tensor([0.8415, 0.4794], grad_fn=<SinBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "grad can be implicitly created only for scalar outputs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-2102fa613706>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this is meant to break! can you fix it??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    118\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
        "y = f(x)\n",
        "describe(y)\n",
        "# this is meant to break! can you fix it??\n",
        "y.backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer**"
      ],
      "metadata": {
        "id": "KiFzNqRJ0t6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# backward() method accumulates gradients into the .grad attributes.\n",
        "# It requires a scalar value to start from, or a gradient to \"pass back\" through\n",
        "# the network.\n",
        "\n",
        "#grad_tensor = torch.ones_like(y)\n",
        "#y.backward(grad_tensor)"
      ],
      "metadata": {
        "id": "ba8C3PpM0MUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi_CJGK_RLy8"
      },
      "source": [
        "Making the output a scalar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tde8QsnrRLy8",
        "outputId": "d1f64f22-9ad9-42ce-a95b-7eb61d310c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5403, 0.8776])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 0.5], requires_grad=True)\n",
        "y = f(x)\n",
        "y.sum().backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-L1c15M6RLy8"
      },
      "source": [
        "but there was an issue.. this isn't right for this edge case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiIlNTJJRLy8",
        "outputId": "0c86e82f-34b2-49d5-c869-d9926cab91a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.8415,  0.8415])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, -1], requires_grad=True)\n",
        "y = f(x)\n",
        "y.sum().backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuTmfhk3RLy8",
        "outputId": "58acd5a3-7ded-4ad3-bf86-04b778946e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4794, 0.8415])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([-0.5, -1], requires_grad=True)\n",
        "y = f(x)\n",
        "y.sum().backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUHPGY3SRLy8"
      },
      "source": [
        "This is because we aren't doing the boolean computation and subsequent application of cos and sin on an elementwise basis.  So, to solve this, it is common to use masking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO6kVCOpRLy8",
        "outputId": "1ea34284-6fff-4b2c-9535-7425d06aec5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5403, 0.8415])\n"
          ]
        }
      ],
      "source": [
        "def f2(x):\n",
        "    mask = torch.gt(x, 0).float()\n",
        "    return mask * torch.sin(x) + (1 - mask) * torch.cos(x)\n",
        "\n",
        "x = torch.tensor([1.0, -1], requires_grad=True)\n",
        "y = f2(x)\n",
        "y.sum().backward()\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDhVdXNcRLy9"
      },
      "outputs": [],
      "source": [
        "def describe_grad(x):\n",
        "    if x.grad is None:\n",
        "        print(\"No gradient information\")\n",
        "    else:\n",
        "        print(\"Gradient: \\n{}\".format(x.grad))\n",
        "        print(\"Gradient Function: {}\".format(x.grad_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ublEFtVRLy9",
        "outputId": "101416d9-40cd-4933-d7e8-812d6568e8fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "No gradient information\n",
            "--------\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[21., 21.],\n",
            "        [21., 21.]], grad_fn=<AddBackward0>)\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([])\n",
            "Values: \n",
            "21.0\n",
            "No gradient information\n",
            "--------\n",
            "Gradient: \n",
            "tensor([[2.2500, 2.2500],\n",
            "        [2.2500, 2.2500]], grad_fn=<CopyBackwards>)\n",
            "Gradient Function: None\n",
            "--------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:251: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at ../torch/csrc/autograd/engine.cpp:1171.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "describe(x)\n",
        "describe_grad(x)\n",
        "print(\"--------\")\n",
        "\n",
        "y = (x + 2) * (x + 5) + 3\n",
        "describe(y)\n",
        "z = y.mean()\n",
        "describe(z)\n",
        "describe_grad(x)\n",
        "print(\"--------\")\n",
        "z.backward(create_graph=True, retain_graph=True)\n",
        "describe_grad(x)\n",
        "print(\"--------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlpA1ybKRLy9"
      },
      "outputs": [],
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Op2owhiRLy9"
      },
      "outputs": [],
      "source": [
        "y = x + 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKz0LtbdRLy9",
        "outputId": "e96b9228-d18c-4cf1-f6bf-90c0da39f201"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AddBackward0 at 0x7f2664dedab0>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "y.grad_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlc3VZDWRLy9"
      },
      "source": [
        "### CUDA Tensors\n",
        "\n",
        "They are specifically allocated on a GPU for CUDA operations. CUDA, which stands for Compute Unified Device Architecture, is a parallel computing platform and application programming interface (API) model created by NVIDIA. It allows developers to use NVIDIA GPUs for general purpose processing (an approach known as GPGPU, General-Purpose computing on Graphics Processing Units)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.youtube.com/embed/r9IqwpMR9TE?si=IYtbYya_rpxv1a1N\"\n",
        "iframe = IFrame(url, width=560, height=315)\n",
        "display.display(iframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "-o_pX8ANr2bH",
        "outputId": "c2d37109-9421-46bf-ec61-d70f3886a52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f2664deddb0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"560\"\n",
              "            height=\"315\"\n",
              "            src=\"https://www.youtube.com/embed/r9IqwpMR9TE?si=IYtbYya_rpxv1a1N\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyxVB9bfRLy9"
      },
      "source": [
        "PyTorch's operations can seamlessly be used on the GPU or on the CPU.  There are a couple basic operations for interacting in this way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2aunVbTRLy9",
        "outputId": "403202de-2340-4d1b-e670-5df44a3f07d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHAJ80gvRLy9",
        "outputId": "f629c3db-8fe1-429f-c917-bdbbe3012feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[0.9149, 0.3993, 0.1100],\n",
            "        [0.2541, 0.4333, 0.4451],\n",
            "        [0.4966, 0.7865, 0.6604]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(3,3)\n",
        "describe(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSVTlDYCRLy-",
        "outputId": "1b7ab5eb-aea3-4d52-e0e9-932662424507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WofZ1MZeRLy-",
        "outputId": "1fc8c2a9-f802-425f-9573-db0043529d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.cuda.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[0.1303, 0.3498, 0.3824],\n",
            "        [0.8043, 0.3186, 0.2908],\n",
            "        [0.4196, 0.3728, 0.3769]], device='cuda:0')\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(3, 3).to(device)\n",
        "describe(x)\n",
        "print(x.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeUeJNTARLy-"
      },
      "outputs": [],
      "source": [
        "cpu_device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "WSFmY-RSRLy-",
        "outputId": "9cf2bd25-5c46-4f8f-a550-1d62a9cd12b9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-1a60be9b141d>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# this will break!\n",
        "y = torch.rand(3, 3).to(\"cuda\")\n",
        "x = torch.rand(3, 3)\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VDEzuwwRLy-",
        "outputId": "4dc7d758-9785-4f15-8acf-7fc2ea4d31f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0585, 1.2775, 0.8134],\n",
              "        [0.6739, 1.0903, 1.0006],\n",
              "        [1.3825, 1.4515, 1.0409]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "y = y.to(cpu_device)\n",
        "x = x.to(cpu_device)\n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "sJyZiY7tRLy-",
        "outputId": "0f3a2692-ec3d-4529-884f-77e99b3ba866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0928, 0.0719, 0.8733],\n",
            "        [0.3230, 0.7917, 0.5447],\n",
            "        [0.6220, 0.1668, 0.3932]], device='cuda:0')\n",
            "tensor([[0.8298, 0.7293, 0.3554],\n",
            "        [0.5615, 0.8828, 0.0619],\n",
            "        [0.8212, 0.3497, 0.3983]], device='cuda:0')\n",
            "tensor([[0.9227, 0.8013, 1.2287],\n",
            "        [0.8845, 1.6745, 0.6066],\n",
            "        [1.4432, 0.5165, 0.7915]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-0ad751b39f5c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Error expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): # only is GPU is available\n",
        "    a = torch.rand(3,3).to(device='cuda:0') #  CUDA Tensor\n",
        "    print(a)\n",
        "\n",
        "    b = torch.rand(3,3).cuda()\n",
        "    print(b)\n",
        "\n",
        "    print(a + b)\n",
        "\n",
        "    # Error expected\n",
        "    a = a.cpu()\n",
        "    print(a + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-pURLg7RRLy-"
      },
      "source": [
        "### Exercises\n",
        "(Answers are at the bottom)\n",
        "\n",
        "#### References\n",
        "\n",
        "1. PyTorch documentation. (2023). PyTorch 2.2 documentation. [https://pytorch.org/docs/stable/index.html](https://pytorch.org/docs/stable/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnwm1XuBRLy-"
      },
      "source": [
        "#### Exercise 1\n",
        "\n",
        "Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G6vv75TRLy-",
        "outputId": "e630efa8-4f06-459f-942b-802e8ffcc43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([3, 3])\n",
            "Values: \n",
            "tensor([[0.3548, 0.4695, 0.9934],\n",
            "        [0.5161, 0.3650, 0.5073],\n",
            "        [0.2586, 0.2099, 0.3873]])\n",
            "Type: torch.FloatTensor\n",
            "Shape/size: torch.Size([1, 3, 3])\n",
            "Values: \n",
            "tensor([[[0.3548, 0.4695, 0.9934],\n",
            "         [0.5161, 0.3650, 0.5073],\n",
            "         [0.2586, 0.2099, 0.3873]]])\n"
          ]
        }
      ],
      "source": [
        "t = torch.rand(3,3)\n",
        "describe(t)\n",
        "describe(t.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Me1pa1NRLy_"
      },
      "source": [
        "#### Exercise 2\n",
        "\n",
        "Remove the extra dimension you just added to the previous tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnWUEul2RLy_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35NsHLXYRLy_"
      },
      "source": [
        "#### Exercise 3\n",
        "\n",
        "Create a random tensor of shape 5x3 in the interval [3, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qddZrqfCRLy_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um3MBLYGRLy_"
      },
      "source": [
        "#### Exercise 4\n",
        "\n",
        "Create a tensor with values from a normal distribution (mean=0, std=1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw6vBsgFRLy_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KZvLVdNRLy_"
      },
      "source": [
        "#### Exercise 5\n",
        "\n",
        "Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCU9QqLpRLy_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCmxpUCJRLy_"
      },
      "source": [
        "#### Exercise 6\n",
        "\n",
        "Create a random tensor of size (3,1) and then horizonally stack 4 copies together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEr5a34qRLy_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYerr16HRLy_"
      },
      "source": [
        "#### Exercise 7\n",
        "\n",
        "Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zzi6Mlb7RLzA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZDjaEjdRLzA"
      },
      "source": [
        "#### Exercise 8\n",
        "\n",
        "Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ4q462DRLzA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyDYp7YeRLzA"
      },
      "source": [
        "### Answers below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "2_vgcfhURLzB"
      },
      "source": [
        "#### Exercise 1\n",
        "\n",
        "Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31umsAu7RLzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44feeb16-b71c-49f9-859f-26b884fdf06f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.7590, 0.4613, 0.3829],\n",
            "         [0.7077, 0.7774, 0.4077],\n",
            "         [0.3737, 0.5846, 0.2281]]])\n",
            "torch.Size([1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = torch.rand(3,3)\n",
        "a = a.unsqueeze(0)\n",
        "print(a)\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wCBZyfI6RLzB"
      },
      "source": [
        "#### Exercise 2\n",
        "\n",
        "Remove the extra dimension you just added to the previous tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1673yA4RLzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94003315-f11b-4209-92a5-8173f1847998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "a = a.squeeze(0)\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "PaJ_7ZoWRLzB"
      },
      "source": [
        "#### Exercise 3\n",
        "\n",
        "Create a random tensor of shape 5x3 in the interval [3, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJhPgH1ZRLzB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e542867f-d5a3-40ad-b06f-eb13ff10f5dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[6.4738, 4.4420, 4.3268],\n",
              "        [6.8291, 3.4517, 4.4619],\n",
              "        [6.8098, 4.0708, 4.5817],\n",
              "        [6.9178, 4.3381, 5.9233],\n",
              "        [5.8582, 5.3859, 3.3046]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "3 + torch.rand(5, 3) * 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FBYfr0NnRLzB"
      },
      "source": [
        "#### Exercise 4\n",
        "\n",
        "Create a tensor with values from a normal distribution (mean=0, std=1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLLLRja7RLzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d682224d-16c0-4fc9-eb1a-639573cdcc5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.8255, -0.2081, -2.7868],\n",
              "        [ 0.0690, -0.8668, -1.6397],\n",
              "        [ 0.4401, -0.6408, -0.2225]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "a = torch.rand(3,3)\n",
        "a.normal_(mean=0, std=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVzIGM3URLzC"
      },
      "source": [
        "#### Exercise 5\n",
        "\n",
        "Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn7b4a2aRLzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ed63ed-39e7-454d-8f93-07edac885d81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [1],\n",
              "        [2],\n",
              "        [4]])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "a = torch.Tensor([1, 1, 1, 0, 1])\n",
        "torch.nonzero(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5fzBlM9RLzC"
      },
      "source": [
        "#### Exercise 6\n",
        "\n",
        "Create a random tensor of size (3,1) and then horizonally stack 4 copies together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY4Fol_ORLzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4808d57-3605-417b-8350-99e335c3c534"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5658, 0.5658, 0.5658, 0.5658],\n",
              "        [0.3595, 0.3595, 0.3595, 0.3595],\n",
              "        [0.8644, 0.8644, 0.8644, 0.8644]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "a = torch.rand(3,1)\n",
        "a.expand(3,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzDKzqJjRLzC"
      },
      "source": [
        "#### Exercise 7\n",
        "\n",
        "Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fz-wZ6eQRLzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc91ac5-1665-47f2-a250-12cff3a0dc09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.9773, 1.2513, 0.9394, 0.7541],\n",
              "         [1.5457, 0.9956, 0.8010, 0.7568],\n",
              "         [1.3365, 1.1201, 0.7146, 0.8631],\n",
              "         [1.2568, 1.1302, 0.7949, 0.5394]],\n",
              "\n",
              "        [[1.6397, 0.5664, 1.1825, 0.5776],\n",
              "         [2.6279, 1.4756, 2.0715, 2.1855],\n",
              "         [1.7314, 0.7973, 1.3998, 1.4142],\n",
              "         [2.2963, 1.0524, 1.8342, 1.6948]],\n",
              "\n",
              "        [[0.8985, 0.8017, 1.7608, 2.5398],\n",
              "         [1.6098, 1.3069, 1.2661, 2.6109],\n",
              "         [0.7039, 0.8116, 1.1718, 1.7193],\n",
              "         [1.2271, 1.0514, 1.3088, 2.4116]]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "a = torch.rand(3,4,5)\n",
        "b = torch.rand(3,5,4)\n",
        "torch.bmm(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pcrfboKgRLzC"
      },
      "source": [
        "#### Exercise 8\n",
        "\n",
        "Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pvsg4iiRLzC",
        "outputId": "8c3638d8-538d-4997-cba8-9a2b976eba7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8311, 1.2736, 1.3916, 1.4931],\n",
              "         [0.5064, 0.7760, 0.5970, 1.1074],\n",
              "         [0.7568, 1.0016, 0.9675, 1.2992],\n",
              "         [0.3438, 0.7510, 1.0245, 1.1805]],\n",
              "\n",
              "        [[0.5998, 0.9879, 1.0517, 1.1733],\n",
              "         [0.8719, 1.1353, 1.3301, 1.4210],\n",
              "         [0.4408, 0.6978, 0.6167, 0.5383],\n",
              "         [0.7010, 0.9677, 0.9617, 1.0903]],\n",
              "\n",
              "        [[1.3839, 1.7990, 1.8216, 1.8963],\n",
              "         [0.8388, 1.1435, 1.0487, 1.2381],\n",
              "         [0.7265, 0.7407, 0.8712, 0.5538],\n",
              "         [1.1645, 1.4835, 1.5728, 1.6886]]])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "a = torch.rand(3,4,5)\n",
        "b = torch.rand(5,4)\n",
        "torch.bmm(a, b.unsqueeze(0).expand(a.size(0), *b.size()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "oYQcjef4RLzC"
      },
      "source": [
        "### END"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}